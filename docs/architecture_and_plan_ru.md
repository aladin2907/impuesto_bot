# TuExpertoFiscal NAIL: ИИ налоговый бот - Архитектура и план разработки

Этот документ описывает архитектуру, технологический стек, схему базы данных и пошаговый план разработки ИИ-бота налогового эксперта для Испании.

## 1. Архитектура системы

Система построена на архитектуре **RAG (Retrieval-Augmented Generation)** — поиск + генерация.

- **Сборщики данных (Data Ingesters):** Скрипты для парсинга Telegram-групп, скрапинга новостных сайтов и обработки официальных документов (например, Налоговый кодекс Испании).
- **База знаний (Knowledge Base):**
    - **Elasticsearch:** Основной поисковый движок, используется для мощного гибридного поиска (семантический векторный поиск + полнотекстовый поиск по ключевым словам) для нахождения наиболее релевантной информации.
    - **Supabase (PostgreSQL):** Основная реляционная база данных для хранения структурированных данных: профили пользователей, история диалогов, подписки, метаданные документов.
- **ИИ ядро (AI Core):**
    - **Оркестратор (LangChain):** Управляет RAG-пайплайном. Принимает вопрос пользователя, ищет контекст в Elasticsearch и формирует точный промпт для LLM.
    - **LLM (Большая языковая модель):** Генерирует финальный, похожий на человеческий ответ на основе вопроса пользователя и найденного контекста. Поддерживаем несколько провайдеров через LangChain.
- **API и интерфейс мессенджеров:**
    - **FastAPI Backend:** API-сервер на Python, который обрабатывает входящие запросы от платформ мессенджеров.
    - **Адаптеры мессенджеров (aiogram):** Модули для взаимодействия с API различных платформ (Telegram, WhatsApp).

## 2. Технологический стек

- **Язык бэкенда:** Python 3.11+
- **Фреймворк бэкенда:** FastAPI
- **ИИ/RAG фреймворк:** LangChain (единый интерфейс для работы с LLM + RAG-цепочки)
- **LLM-провайдеры (через LangChain):**
  - OpenAI (GPT-4o, GPT-4o-mini)
  - Google Gemini (gemini-pro, gemini-1.5-flash)
  - Anthropic Claude (claude-3.5-sonnet)
  - OpenRouter (доступ к 100+ моделям)
- **Поисковый движок и векторная БД:** Elasticsearch (Elastic Cloud) + интеграция с LangChain
- **Реляционная БД:** Supabase (PostgreSQL)
- **Telegram бот:** aiogram
- **Деплой (в планах):** Docker, Cloud Run/Render/Heroku

## 3. Схема базы данных (Supabase/PostgreSQL)

База данных спроектирована для поддержки нескольких платформ и модели подписок.

- **`users`**: Основные профили пользователей.
- **`user_channels`**: Связывает пользователей с их аккаунтами на разных платформах мессенджеров (Telegram, WhatsApp).
- **`dialogue_sessions`**: Группирует разговоры для контекста и суммаризации.
- **`messages`**: Хранит каждое отдельное сообщение для истории и анализа.
- **`user_tax_profile`**: Хранит персональные данные для налоговых расчётов.
- **`documents`**: Метаданные исходных документов, которые обрабатываются и индексируются в Elasticsearch.

(Полный SQL-скрипт доступен в `database/schema.sql`)

## 4. Пошаговый план разработки

### Фаза 1: Фундамент (завершено)

1.  **[✓] Настройка проекта:** Базовая структура, зависимости, окружение.
2.  **[✓] LLM/поисковые сервисы:** Единый LLM-сервис, клиенты Supabase и Elasticsearch.
3.  **[✓] Схемы данных:** Актуальные таблицы `users`, `messages`, `documents` и др.
4.  **[✓] API и базовый поиск:** FastAPI вебхук (`app/api/webhook.py`) + `SearchService` с гибридным поиском и сохранением истории.
5.  **[✓] Сбор данных:** Выгрузка Telegram, подготовленные наборы календаря, новостей и PDF.

### Фаза 2: Автоматизация сбора и индексации

1.  **[ ] Унифицировать `BaseIngestor`:** единая инициализация LLM/ES/Supabase, логирование, обработка ошибок.
2.  **[ ] Реализовать недостающие инжесторы:**
    - `ingest_tax_calendar.py` — парсинг календаря + запись в Supabase и Elasticsearch.
    - `ingest_news_articles.py` — ежедневный скрапинг и обновление новостей.
    - `ingest_aeat_website.py`, `ingest_valencia_dogv.py` — официальные и региональные источники.
3.  **[ ] Связать загрузку и индексацию:** после записи в БД запускать индексаторы или встроить индексацию в сами инжесторы.
4.  **[ ] Настроить расписания:** cron/GitHub Actions для Telegram (еженедельно), новостей (ежедневно), календаря и PDF (по событиям).
5.  **[ ] Контроль качества данных:** отчёты по объёму, дедупликация, хранение `last_synced_at`.

### Фаза 3: Поиск по каждому источнику

1.  **[ ] Развести индексы/алиасы в Elasticsearch** по источникам (telegram/news/pdf/calendar/aeat/regional).
2.  **[ ] Добавить специализированные методы поиска** в `SearchService` (например, `search_pdf`, `search_news`) с учётом специфики метаданных.
3.  **[ ] Обновить API:** отдельные эндпоинты (`/search/pdf`, `/search/news`) либо единый `/search` с параметром `sources`.
4.  **[ ] Обновить документацию и примеры** (Swagger, `docs/N8N_EXAMPLES.md`) под новый контракт.
5.  **[ ] Интеграционные тесты:** покрыть поиск по отдельным источникам и их комбинациям.

### Фаза 4: Интеграция с n8n

1.  **[ ] Новый эндпоинт для n8n** (например, `/n8n/search`): принимает список источников, текст запроса и метаданные рабочего процесса.
2.  **[ ] Маршрутизация и агрегация:** запуск поиска по каждому источнику, объединение и нормализация результатов.
3.  **[ ] Обратная отправка:** POST на `https://n8n.mafiavlc.org/webhook/59c06e61-a477-42df-8959-20f056f33189` с детальной структурой результата.
4.  **[ ] Логирование и ретраи:** хранить статусы запросов, повторять отправку при ошибках.
5.  **[ ] E2E тесты и обновлённые примеры** в `docs/N8N_EXAMPLES.md` и автотестах.

### Фаза 5: Эксплуатация и масштабирование

1.  **[ ] Мониторинг и алерты:** метрики индексации, скорости поиска, интеграций n8n.
2.  **[ ] Кеширование и квоты:** ограничение нагрузки, кеш популярных запросов.
3.  **[ ] Резервное копирование:** регулярные бэкапы Supabase и снапшоты Elasticsearch.
4.  **[ ] Дополнительные каналы:** расширение на WhatsApp/веб при готовности инфраструктуры.
5.  **[ ] Подготовка к продакшену:** Docker/CI, управление секретами, нагрузочные тесты.

## 5. Преимущества использования LangChain

### Почему LangChain?

1. **Единый интерфейс для всех LLM:** OpenAI, Google, Anthropic, OpenRouter — все работают через один API.
2. **Готовые RAG-компоненты:** Не нужно писать с нуля — document loaders, text splitters, vector stores, retrievers — всё есть.
3. **Гибридный поиск из коробки:** `ElasticsearchStore` уже поддерживает комбинацию семантического и keyword-поиска.
4. **Управление памятью:** Встроенные `Memory` классы для ведения контекста диалога.
5. **Production-ready:** Тысячи компаний используют в продакшене, активная разработка, много примеров.
6. **Async/await:** Поддержка асинхронности для высокой производительности.
7. **Callbacks и мониторинг:** Легко отслеживать токены, стоимость, время выполнения.

### Пример кода

```python
from langchain.chains import RetrievalQA
from langchain_elasticsearch import ElasticsearchStore
from app.services.llm import llm_service

# Инициализация
llm_service.initialize()

# Создание retriever из Elasticsearch
vectorstore = ElasticsearchStore(
    es_connection=elastic_client,
    index_name="tuexpertofiscal_knowledge",
    embedding=llm_service.embeddings_model
)

# Создание RAG-цепочки
qa_chain = RetrievalQA.from_chain_type(
    llm=llm_service.chat_model,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    return_source_documents=True
)

# Запрос
result = qa_chain("Что такое IRPF в Испании?")
print(result['result'])  # Ответ
print(result['source_documents'])  # Источники
```

## 6. Структура проекта

```
impuesto_bot/
├── app/
│   ├── config/              # Конфигурация и настройки
│   │   └── settings.py
│   ├── services/            # Бизнес-логика
│   │   ├── llm/            # LLM сервис (LangChain)
│   │   ├── elasticsearch_service.py
│   │   └── supabase_service.py
│   ├── models/             # Модели данных
│   └── utils/              # Вспомогательные функции
├── scripts/                # Скрипты загрузки данных и автоматизации
├── database/               # SQL-схемы и миграции
├── docs/                   # Документация
│   ├── architecture_and_plan.md     # План (английский)
│   ├── architecture_and_plan_ru.md  # План (русский)
│   └── llm_providers_guide.md       # Гайд по LLM
└── tests/                  # Тесты
```

## 7. Следующие шаги

Мы уже прошли следующие пункты:
- ✅ Базовая структура проекта
- ✅ Конфигурация с `.env`
- ✅ LLM-сервис с поддержкой 4 провайдеров
- ✅ Сервисы для Elasticsearch и Supabase
- ✅ SQL-схема базы данных
- ✅ **Схема БД развёрнута в Supabase (https://mslfndlzjqttteihiopt.supabase.co)**
- ✅ Список источников данных с Telegram-группами

**Что дальше:**
1. Написать скрипт загрузки документов (Налоговый кодекс) с LangChain
2. Настроить гибридный поиск в Elasticsearch
3. Создать первую рабочую RAG-цепочку
4. Интегрировать с Telegram

---

*Разработано NAIL - Nahornyi AI Lab*
