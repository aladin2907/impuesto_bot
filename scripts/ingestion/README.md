# Data Ingestion Scripts

This directory contains scripts for ingesting different types of data into the TuExpertoFiscal NAIL knowledge base.

## Architecture Principle

‚ö†Ô∏è **IMPORTANT:** Each data source type has its own specialized script. Do not create universal scripts.

Each source has unique requirements:
- **PDF laws** - Article extraction, legal structure
- **Tax calendar** - Date parsing, deadline tracking, dual storage (Elasticsearch + Supabase)
- **Telegram** - Spam filtering, Q&A extraction, anonymization
- **News** - RSS parsing, duplicate detection, freshness scoring
- **AEAT** - Structured HTML, form instructions, calculator integration

See `docs/ingestion_architecture.md` for detailed design.

## Structure

```
scripts/ingestion/
‚îú‚îÄ‚îÄ base_ingestor.py              # Base class with common functionality
‚îú‚îÄ‚îÄ ingest_pdf_documents.py       # ‚úÖ Tax laws & regulations
‚îú‚îÄ‚îÄ ingest_tax_calendar.py        # üìÖ Tax calendar (special date handling)
‚îú‚îÄ‚îÄ sync_aeat_calendar.py         # üîÑ AEAT iCalendar synchronisation
‚îú‚îÄ‚îÄ ingest_telegram_groups.py     # üí¨ Telegram Q&A discussions
‚îú‚îÄ‚îÄ ingest_news_articles.py       # üì∞ News articles
‚îú‚îÄ‚îÄ ingest_aeat_website.py        # üèõÔ∏è AEAT official resources
‚îî‚îÄ‚îÄ ingest_valencia_dogv.py       # üèõÔ∏è Valencia regional documents
```

## Available Scripts

### 1. PDF Document Ingestion

Ingests PDF files such as Tax Code, Tax Calendar, and regulations.

**Usage:**
```bash
python scripts/ingestion/ingest_pdf_documents.py <path_to_pdf> [options]
```

**Options:**
- `--url <source_url>`: Original URL of the document
- `--type <document_type>`: Type of document (tax_code, tax_calendar, regulation, guide)

**Examples:**

```bash
# Ingest Spanish Tax Code (IRPF)
python scripts/ingestion/ingest_pdf_documents.py \
    data/raw_documents/ley_35_2006_irpf.pdf \
    --url "https://www.boe.es/buscar/act.php?id=BOE-A-2006-20764" \
    --type tax_code

# Ingest Tax Calendar
python scripts/ingestion/ingest_pdf_documents.py \
    data/raw_documents/calendario_fiscal_2024.pdf \
    --url "https://sede.agenciatributaria.gob.es/Sede/ayuda/calendario-contribuyente.html" \
    --type tax_calendar

# Ingest Valencia regional regulation
python scripts/ingestion/ingest_pdf_documents.py \
    data/raw_documents/valencia_medidas_fiscales_2024.pdf \
    --type regulation
```

**What it does:**
1. Loads the PDF file
2. Splits into chunks (1000 chars with 200 overlap)
3. Generates embeddings using configured LLM
4. Indexes into Elasticsearch with hybrid search enabled
5. Saves metadata to Supabase `documents` table

### 2. AEAT iCalendar Sync

Pulls official AEAT calendars (`.ics`) hosted on Google Calendar, parses events and upserts them into Supabase.

**Usage (alpha):**
```bash
python scripts/ingestion/sync_aeat_calendar.py
```

**Features:**
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö .ics —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ AEAT.
- –ü–∞—Ä—Å–∏—Ç VEVENT –∑–∞–ø–∏—Å–∏ (UID, SUMMARY, DTSTART, STATUS, SEQUENCE, etc.).
- Upsert –≤ —Ç–∞–±–ª–∏—Ü—É `calendar_events` –ø–æ `(uid, calendar_type)` —Å –ø–æ–º–µ—Ç–∫–æ–π –æ—Ç–º–µ–Ω—ë–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π.

**TODO:**
- –û–±–≤—è–∑–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è (cron/GitHub Actions).
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–∞–ø–ø–∏–Ω–≥ —Å–æ–±—ã—Ç–∏–π –≤ `calendar_deadlines` –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.

### 3. Tax Calendar Ingestion

Parses structured AEAT calendar data (JSON) and –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤ –ø–æ–∏—Å–∫–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.

**Usage (WIP):**
```bash
python scripts/ingestion/ingest_tax_calendar.py data/tax_calendar.json
```

**What is ready:**
- TDD-–ø–æ–∫—Ä—ã—Ç—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–µ–¥–ª–∞–π–Ω–æ–≤ (`tests/test_ingest_tax_calendar.py`)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è —Å –±–æ–≥–∞—Ç—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

**Next steps:**
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Supabase –∏ Elasticsearch —á–µ—Ä–µ–∑ `BaseIngestor`
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π

### 4. News Articles Ingestion

Processes –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –≤—ã–≥—Ä—É–∑–∫–∏ (`news_articles.json`), —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å–∏.

**Usage:**
```bash
python scripts/ingestion/ingest_news_articles.py data/news_articles.json
```

**Features:**
- –î–µ–¥—É–±–ª–∏–∫–∞—Ü–∏—è –ø–æ `article_url` (—É—á–∏—Ç—ã–≤–∞–µ—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏ –≤ Supabase).
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ `news_articles_metadata` –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ Elasticsearch.
- –ì–æ—Ç–æ–≤–æ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é (e.g. daily cron).

### 5. AEAT Resources Ingestion

Processes –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã AEAT (PDF/HTML –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, —Ñ–æ—Ä–º—ã) –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –∏–Ω–¥–µ–∫—Å.

**Usage:**
```bash
python scripts/ingestion/ingest_aeat_website.py data/aeat_resources.json
```

**Features:**
- –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ `resource_url`, —É—á—ë—Ç —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π (`aeat_resources_metadata`).
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏, –≥–æ–¥, –≤–µ—Ä—Å–∏—è) –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ Elasticsearch.
- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –µ–∂–µ–º–µ—Å—è—á–Ω–æ–≥–æ –∏–ª–∏ —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞.

### 6. Valencia DOGV Ingestion

Handles —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã DOGV (Valencia) –∏–∑ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–≥–æ JSON.

**Usage: **
```bash
python scripts/ingestion/ingest_valencia_dogv.py data/valencia_dogv.json
```

**Features:**
- –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ `source_url`, –ø—Ä–æ–≤–µ—Ä–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤ `pdf_documents_metadata`.
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–Ω–∞–∑–≤–∞–Ω–∏–µ, –¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏, —Ä–µ–≥–∏–æ–Ω) –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞.
- –ì–æ—Ç–æ–≤ –∫ —Ä—É—á–Ω–æ–º—É –∏–ª–∏ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–º—É –∑–∞–ø—É—Å–∫—É –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∑–∞–∫–æ–Ω–æ–≤.

### 7. Telegram Groups (Coming Soon)

Will parse Telegram groups weekly and extract valuable discussions.

### 8. AEAT Website (Coming Soon)

Will scrape AEAT official website for FAQs and guides.

## Common Workflow

All ingestion scripts follow this pattern:

1. **Initialize Services**
   - LLM service (for embeddings)
   - Elasticsearch (for indexing)
   - Supabase (for metadata)

2. **Load Data**
   - Load from source (PDF, web, etc.)

3. **Process**
   - Split into chunks
   - Generate embeddings
   - Add metadata

4. **Store**
   - Index in Elasticsearch
   - Save metadata in Supabase

5. **Cleanup**
   - Close connections

## Configuration

All scripts use settings from `.env`:

```env
# LLM for embeddings
LLM_PROVIDER=openai
OPENAI_API_KEY=...

# Elasticsearch
ELASTIC_CLOUD_ID=...
ELASTIC_API_KEY=...
ELASTIC_INDEX_NAME=tuexpertofiscal_knowledge

# Supabase
SUPABASE_DB_URL=...
```

## Data Storage

- **Raw files:** Store in `data/raw_documents/`
- **Elasticsearch:** Processed chunks with embeddings
- **Supabase:** Document metadata and status

## Development

To create a new ingestor:

1. Create new file: `ingest_<source>.py`
2. Inherit from `BaseIngestor`
3. Implement source-specific loading logic
4. Use parent class methods for common operations

Example:
```python
from scripts.ingestion.base_ingestor import BaseIngestor

class MyIngestor(BaseIngestor):
    def __init__(self):
        super().__init__(document_type="my_type")
    
    def load_data(self, source):
        # Your loading logic
        pass
    
    def process(self, source):
        self.initialize()
        docs = self.load_data(source)
        self.ingest_documents(docs)
        self.cleanup()
```

---

*Developed by NAIL - Nahornyi AI Lab*
