#!/usr/bin/env python3
"""
–í–∫–ª—é—á–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
1. –î–æ–±–∞–≤–ª—è–µ—Ç dense_vector –ø–æ–ª—è –≤ mapping
2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç embeddings –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
3. –û–±–Ω–æ–≤–ª—è–µ—Ç search_service.py
"""

import os
import sys
import json
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.elasticsearch.elasticsearch_service import ElasticsearchService
from app.services.llm.llm_service import LLMService
from app.config.settings import Settings

settings = Settings()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ (—Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)
INDICES_CONFIG = {
    "telegram_threads": {
        "text_field": "content",
        "embedding_field": "content_embedding"
    },
    "pdf_documents": {
        "text_field": "content",
        "embedding_field": "content_embedding"
    }
}


def add_vector_field_to_mapping(es_service: ElasticsearchService, index_name: str, embedding_field: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç dense_vector –ø–æ–ª–µ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å"""
    
    print(f"\nüîß –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ mapping –¥–ª—è {index_name}...")
    
    # OpenAI text-embedding-3-small –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 1536
    mapping = {
        "properties": {
            embedding_field: {
                "type": "dense_vector",
                "dims": 1536,
                "index": True,
                "similarity": "cosine"
            }
        }
    }
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        if not es_service.index_exists(index_name):
            print(f"‚ö†Ô∏è  –ò–Ω–¥–µ–∫—Å {index_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –≤ mapping —á–µ—Ä–µ–∑ requests API
        import requests
        url = f"{es_service.base_url}/{index_name}/_mapping"
        response = requests.put(
            url,
            headers=es_service.headers,
            json=mapping,
            timeout=30
        )
        
        if response.status_code == 200:
            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ {embedding_field} –≤ {index_name}")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è mapping: {response.status_code}")
            print(f"   {response.text[:300]}")
            return False
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è mapping: {e}")
        return False


def generate_embeddings_for_index(
    es_service: ElasticsearchService,
    llm_service: LLMService,
    index_name: str,
    text_field: str,
    embedding_field: str,
    batch_size: int = 50
):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç embeddings –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ"""
    
    print(f"\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings –¥–ª—è {index_name}...")
    
    try:
        import requests
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        count_url = f"{es_service.base_url}/{index_name}/_count"
        count_response = requests.get(count_url, headers=es_service.headers, timeout=30)
        count_response.raise_for_status()
        total_docs = count_response.json()['count']
        print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}")
        
        if total_docs == 0:
            print("‚ö†Ô∏è  –ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç–æ–π")
            return 0
        
        # Scroll API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        scroll_time = '5m'
        search_url = f"{es_service.base_url}/{index_name}/_search?scroll={scroll_time}"
        search_body = {
            "query": {"match_all": {}},
            "_source": [text_field],
            "size": batch_size
        }
        
        response = requests.post(search_url, headers=es_service.headers, json=search_body, timeout=30)
        response.raise_for_status()
        result = response.json()
        
        scroll_id = result['_scroll_id']
        hits = result['hits']['hits']
        
        processed = 0
        updated = 0
        
        while hits:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –±–∞—Ç—á –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings
            texts = []
            doc_ids = []
            
            for hit in hits:
                text = hit['_source'].get(text_field, '')
                if text and len(text.strip()) > 0:
                    texts.append(text[:8000])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è API
                    doc_ids.append(hit['_id'])
            
            if texts:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings –±–∞—Ç—á–æ–º
                try:
                    embeddings = llm_service.generate_embeddings_batch(texts)
                    
                    if embeddings and len(embeddings) == len(texts):
                        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ bulk API
                        bulk_url = f"{es_service.base_url}/_bulk"
                        bulk_lines = []
                        for doc_id, embedding in zip(doc_ids, embeddings):
                            bulk_lines.append(json.dumps({"update": {"_id": doc_id, "_index": index_name}}))
                            bulk_lines.append(json.dumps({"doc": {embedding_field: embedding}}))
                        
                        bulk_body = "\n".join(bulk_lines) + "\n"
                        headers = es_service.headers.copy()
                        headers["Content-Type"] = "application/x-ndjson"
                        
                        bulk_response = requests.post(bulk_url, headers=headers, data=bulk_body, timeout=60)
                        
                        if bulk_response.status_code == 200:
                            updated += len(embeddings)
                        else:
                            print(f"‚ö†Ô∏è  Bulk update –≤–µ—Ä–Ω—É–ª {bulk_response.status_code}")
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings –¥–ª—è –±–∞—Ç—á–∞: {e}")
            
            processed += len(hits)
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{total_docs}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –±–∞—Ç—á
            scroll_url = f"{es_service.base_url}/_search/scroll"
            scroll_body = {"scroll": scroll_time, "scroll_id": scroll_id}
            scroll_response = requests.post(scroll_url, headers=es_service.headers, json=scroll_body, timeout=30)
            scroll_response.raise_for_status()
            result = scroll_response.json()
            scroll_id = result['_scroll_id']
            hits = result['hits']['hits']
        
        # –û—á–∏—â–∞–µ–º scroll
        delete_scroll_url = f"{es_service.base_url}/_search/scroll"
        requests.delete(delete_scroll_url, headers=es_service.headers, json={"scroll_id": scroll_id}, timeout=10)
        
        print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {updated} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å embeddings")
        return updated
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings: {e}")
        import traceback
        traceback.print_exc()
        return 0


def main():
    print("=" * 70)
    print("üöÄ –í–ö–õ–Æ–ß–ï–ù–ò–ï –ì–ò–ë–†–ò–î–ù–û–ì–û –ü–û–ò–°–ö–ê")
    print("=" * 70)
    print("\n–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: OpenAI text-embedding-3-small (dims: 1536)")
    print("–ú–µ—Ç—Ä–∏–∫–∞ similarity: cosine")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
    print("\nüì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤...")
    
    es_service = ElasticsearchService()
    if not es_service.ping():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Elasticsearch")
        return 1
    print("‚úÖ Elasticsearch –ø–æ–¥–∫–ª—é—á–µ–Ω")
    
    llm_service = LLMService()
    if not llm_service.initialize():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å LLM service")
        return 1
    print(f"‚úÖ LLM service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {llm_service.provider} / {llm_service.model}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∏–Ω–¥–µ–∫—Å
    total_updated = 0
    
    for index_name, config in INDICES_CONFIG.items():
        print("\n" + "=" * 70)
        print(f"üìÅ –ò–Ω–¥–µ–∫—Å: {index_name}")
        print("=" * 70)
        
        # 1. –î–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø–æ–ª–µ –≤ mapping
        if not add_vector_field_to_mapping(
            es_service=es_service,
            index_name=index_name,
            embedding_field=config["embedding_field"]
        ):
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å {index_name}")
            continue
        
        # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        updated_count = generate_embeddings_for_index(
            es_service=es_service,
            llm_service=llm_service,
            index_name=index_name,
            text_field=config["text_field"],
            embedding_field=config["embedding_field"],
            batch_size=50
        )
        
        total_updated += updated_count
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å {index_name} –≥–æ—Ç–æ–≤ –∫ –≥–∏–±—Ä–∏–¥–Ω–æ–º—É –ø–æ–∏—Å–∫—É")
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 70)
    print(f"‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 70)
    print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ —Å embeddings: {total_updated}")
    print("\nüìã –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
    print("1. –û–±–Ω–æ–≤–∏—Ç—å search_service.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫")
    print("\n–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ = BM25 (keyword) + kNN (vector) + RRF")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

