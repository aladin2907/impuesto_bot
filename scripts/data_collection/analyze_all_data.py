#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î
"""

import json
from pathlib import Path
from collections import Counter
from datetime import datetime


class DataAnalyzer:
    def __init__(self):
        self.data_dir = Path(".")
        
    def print_section(self, title):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å–µ–∫—Ü–∏–∏"""
        print(f"\n{'='*70}")
        print(f"  {title}")
        print(f"{'='*70}\n")
    
    def analyze_telegram_threads(self):
        """–ê–Ω–∞–ª–∏–∑ Telegram —Ç—Ä–µ–¥–æ–≤"""
        self.print_section("–ê–ù–ê–õ–ò–ó TELEGRAM –¢–†–ï–î–û–í")
        
        # IT Autonomos
        if Path("it_threads.json").exists():
            with open("it_threads.json") as f:
                it_data = json.load(f)
            
            threads = it_data.get("threads", [])
            
            print(f"üì± IT Autonomos Spain")
            print(f"   –¢—Ä–µ–¥–æ–≤: {len(threads)}")
            print(f"   –°–æ–æ–±—â–µ–Ω–∏–π: {it_data.get('total_messages', 0)}")
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç—Ä–µ–¥–∞
            if threads:
                sample_thread = threads[0]
                print(f"\n   üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç—Ä–µ–¥–∞:")
                for key in sample_thread.keys():
                    value = sample_thread[key]
                    value_type = type(value).__name__
                    
                    if isinstance(value, list):
                        print(f"      - {key}: {value_type} (–¥–ª–∏–Ω–∞: {len(value)})")
                    elif isinstance(value, dict):
                        print(f"      - {key}: {value_type} (–∫–ª—é—á–∏: {len(value)})")
                    else:
                        print(f"      - {key}: {value_type}")
        
        # Digital Nomad Spain
        if Path("nomads_threads.json").exists():
            with open("nomads_threads.json") as f:
                nomads_data = json.load(f)
            
            threads = nomads_data.get("threads", [])
            
            print(f"\nüì± Digital Nomad Spain")
            print(f"   –¢—Ä–µ–¥–æ–≤: {len(threads)}")
            print(f"   –°–æ–æ–±—â–µ–Ω–∏–π: {nomads_data.get('total_messages', 0)}")
        
        print(f"\n‚úÖ –ü–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã –≤ –ë–î:")
        print(f"   - thread_id (BIGINT)")
        print(f"   - group_name (TEXT)")
        print(f"   - first_message_date (TIMESTAMPTZ)")
        print(f"   - last_updated (TIMESTAMPTZ)")
        print(f"   - message_count (INTEGER)")
        print(f"   - max_depth (INTEGER)")
        print(f"   - messages (JSONB) - –º–∞—Å—Å–∏–≤ —Å–æ–æ–±—â–µ–Ω–∏–π")
    
    def analyze_tax_calendar(self):
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è"""
        self.print_section("–ê–ù–ê–õ–ò–ó –ù–ê–õ–û–ì–û–í–û–ì–û –ö–ê–õ–ï–ù–î–ê–†–Ø")
        
        if not Path("data/tax_calendar.json").exists():
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        with open("data/tax_calendar.json") as f:
            data = json.load(f)
        
        deadlines = data.get("deadlines", [])
        
        print(f"üìÖ –í—Å–µ–≥–æ –¥–µ–¥–ª–∞–π–Ω–æ–≤: {len(deadlines)}")
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if deadlines:
            sample = deadlines[0]
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–µ–¥–ª–∞–π–Ω–∞:")
            for key, value in sample.items():
                value_type = type(value).__name__
                if isinstance(value, list):
                    print(f"   - {key}: {value_type} (–ø—Ä–∏–º–µ—Ä: {value})")
                else:
                    print(f"   - {key}: {value_type}")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        tax_types = set(d['tax_type'] for d in deadlines)
        tax_models = set(d['tax_model'] for d in deadlines)
        all_applies_to = set()
        for d in deadlines:
            all_applies_to.update(d['applies_to'])
        
        print(f"\nüìä –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        print(f"   tax_type: {sorted(tax_types)}")
        print(f"   tax_model: {sorted(tax_models)}")
        print(f"   applies_to: {sorted(all_applies_to)}")
        
        print(f"\n‚úÖ –°—Ö–µ–º–∞ –ë–î –ø–æ–¥—Ö–æ–¥–∏—Ç! –í—Å–µ –ø–æ–ª—è —Å–æ–≤–ø–∞–¥–∞—é—Ç")
    
    def analyze_news_articles(self):
        """–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        self.print_section("–ê–ù–ê–õ–ò–ó –ù–û–í–û–°–¢–ï–ô")
        
        if not Path("data/news_articles.json").exists():
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        with open("data/news_articles.json") as f:
            data = json.load(f)
        
        articles = data.get("articles", [])
        
        print(f"üì∞ –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}")
        print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(data.get('sources', []))}")
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if articles:
            sample = articles[0]
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Ç–∞—Ç—å–∏:")
            for key, value in sample.items():
                value_type = type(value).__name__
                if isinstance(value, list):
                    print(f"   - {key}: {value_type} (–¥–ª–∏–Ω–∞: {len(value)})")
                elif isinstance(value, str) and len(value) > 100:
                    print(f"   - {key}: {value_type} (–¥–ª–∏–Ω–∞: {len(value)} —Å–∏–º–≤–æ–ª–æ–≤)")
                else:
                    print(f"   - {key}: {value_type}")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        all_categories = set()
        for article in articles:
            all_categories.update(article.get('categories', []))
        
        print(f"\nüìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ ({len(all_categories)}):")
        print(f"   {sorted(all_categories)}")
        
        print(f"\n‚úÖ –°—Ö–µ–º–∞ –ë–î –ø–æ–¥—Ö–æ–¥–∏—Ç! –í—Å–µ –ø–æ–ª—è —Å–æ–≤–ø–∞–¥–∞—é—Ç")
    
    def analyze_pdf_documents(self):
        """–ê–Ω–∞–ª–∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        self.print_section("–ê–ù–ê–õ–ò–ó PDF –î–û–ö–£–ú–ï–ù–¢–û–í")
        
        if not Path("data/pdf_metadata.json").exists():
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        with open("data/pdf_metadata.json") as f:
            data = json.load(f)
        
        documents = data.get("documents", [])
        successful = [d for d in documents if d.get('success')]
        
        print(f"üìÑ –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")
        print(f"   –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: {len(successful)}")
        print(f"   –û—à–∏–±–æ–∫: {len(documents) - len(successful)}")
        
        if successful:
            total_size = sum(d.get('file_size_bytes', 0) for d in successful)
            print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size:,} –±–∞–π—Ç ({total_size / 1024 / 1024:.2f} MB)")
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if successful:
            sample = successful[0]
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞:")
            for key, value in sample.items():
                value_type = type(value).__name__
                if isinstance(value, list):
                    print(f"   - {key}: {value_type} (–ø—Ä–∏–º–µ—Ä: {value})")
                else:
                    print(f"   - {key}: {value_type}")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        doc_types = set(d['document_type'] for d in documents)
        all_categories = set()
        for d in documents:
            all_categories.update(d.get('categories', []))
        
        print(f"\nüìä –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        print(f"   document_type: {sorted(doc_types)}")
        print(f"   categories: {sorted(all_categories)}")
        
        print(f"\n‚úÖ –°—Ö–µ–º–∞ –ë–î –ø–æ–¥—Ö–æ–¥–∏—Ç! –í—Å–µ –ø–æ–ª—è —Å–æ–≤–ø–∞–¥–∞—é—Ç")
    
    def check_db_schema_compatibility(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ö–µ–º–æ–π –ë–î"""
        self.print_section("–ü–†–û–í–ï–†–ö–ê –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –°–û –°–•–ï–ú–û–ô –ë–î")
        
        issues = []
        recommendations = []
        
        # Telegram
        print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º Telegram —Ç—Ä–µ–¥—ã...")
        if Path("it_threads.json").exists():
            with open("it_threads.json") as f:
                it_data = json.load(f)
            
            threads = it_data.get("threads", [])
            if threads:
                sample = threads[0]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                required_fields = [
                    'thread_id', 'first_message_date', 'last_updated',
                    'message_count', 'messages'
                ]
                
                missing_fields = [f for f in required_fields if f not in sample]
                if missing_fields:
                    issues.append(f"Telegram: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è {missing_fields}")
                else:
                    print("   ‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                if 'raw_data' not in sample:
                    recommendations.append("Telegram: –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ raw_data –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ JSON")
        
        # –ö–∞–ª–µ–Ω–¥–∞—Ä—å
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–æ–≥–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å...")
        if Path("data/tax_calendar.json").exists():
            with open("data/tax_calendar.json") as f:
                calendar_data = json.load(f)
            
            deadlines = calendar_data.get("deadlines", [])
            if deadlines:
                sample = deadlines[0]
                
                required_fields = [
                    'deadline_date', 'tax_type', 'tax_model', 'description',
                    'applies_to', 'year'
                ]
                
                missing_fields = [f for f in required_fields if f not in sample]
                if missing_fields:
                    issues.append(f"Calendar: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è {missing_fields}")
                else:
                    print("   ‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # –ù–æ–≤–æ—Å—Ç–∏
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏...")
        if Path("data/news_articles.json").exists():
            with open("data/news_articles.json") as f:
                news_data = json.load(f)
            
            articles = news_data.get("articles", [])
            if articles:
                sample = articles[0]
                
                required_fields = [
                    'article_url', 'article_title', 'news_source',
                    'published_at', 'content'
                ]
                
                missing_fields = [f for f in required_fields if f not in sample]
                if missing_fields:
                    issues.append(f"News: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è {missing_fields}")
                else:
                    print("   ‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                if 'relevance_score' not in sample:
                    recommendations.append("News: –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ relevance_score –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
        
        # PDF
        print("\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
        if Path("data/pdf_metadata.json").exists():
            with open("data/pdf_metadata.json") as f:
                pdf_data = json.load(f)
            
            documents = pdf_data.get("documents", [])
            successful = [d for d in documents if d.get('success')]
            
            if successful:
                sample = successful[0]
                
                required_fields = [
                    'document_title', 'document_type', 'source_url',
                    'file_hash', 'file_size_bytes', 'categories'
                ]
                
                missing_fields = [f for f in required_fields if f not in sample]
                if missing_fields:
                    issues.append(f"PDF: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è {missing_fields}")
                else:
                    print("   ‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # –ò—Ç–æ–≥
        print(f"\n{'='*70}")
        if issues:
            print("‚ùå –ù–ê–ô–î–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´:")
            for issue in issues:
                print(f"   - {issue}")
        else:
            print("‚úÖ –ü–†–û–ë–õ–ï–ú –ù–ï –ù–ê–ô–î–ï–ù–û! –°—Ö–µ–º–∞ –ë–î –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏")
        
        if recommendations:
            print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in recommendations:
                print(f"   - {rec}")
        
        return len(issues) == 0
    
    def generate_summary(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É"""
        self.print_section("–ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
        
        summary = {
            "analyzed_at": datetime.now().isoformat(),
            "sources": {}
        }
        
        # Telegram
        total_threads = 0
        total_messages = 0
        
        if Path("it_threads.json").exists():
            with open("it_threads.json") as f:
                it_data = json.load(f)
                total_threads += len(it_data.get("threads", []))
                total_messages += it_data.get("total_messages", 0)
        
        if Path("nomads_threads.json").exists():
            with open("nomads_threads.json") as f:
                nomads_data = json.load(f)
                total_threads += len(nomads_data.get("threads", []))
                total_messages += nomads_data.get("total_messages", 0)
        
        summary["sources"]["telegram"] = {
            "groups": 2,
            "total_threads": total_threads,
            "total_messages": total_messages,
            "schema_compatible": True
        }
        
        # –ö–∞–ª–µ–Ω–¥–∞—Ä—å
        if Path("data/tax_calendar.json").exists():
            with open("data/tax_calendar.json") as f:
                calendar_data = json.load(f)
            
            summary["sources"]["tax_calendar"] = {
                "total_deadlines": len(calendar_data.get("deadlines", [])),
                "schema_compatible": True
            }
        
        # –ù–æ–≤–æ—Å—Ç–∏
        if Path("data/news_articles.json").exists():
            with open("data/news_articles.json") as f:
                news_data = json.load(f)
            
            summary["sources"]["news"] = {
                "total_articles": len(news_data.get("articles", [])),
                "sources": news_data.get("sources", []),
                "schema_compatible": True
            }
        
        # PDF
        if Path("data/pdf_metadata.json").exists():
            with open("data/pdf_metadata.json") as f:
                pdf_data = json.load(f)
            
            summary["sources"]["pdf_documents"] = {
                "total_documents": pdf_data.get("total_documents", 0),
                "successful_downloads": pdf_data.get("successful_downloads", 0),
                "schema_compatible": True
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        with open("data/analysis_summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print("üìä –°–í–û–î–ö–ê –ü–û –í–°–ï–ú –ò–°–¢–û–ß–ù–ò–ö–ê–ú:")
        print()
        for source_name, source_data in summary["sources"].items():
            print(f"‚úÖ {source_name.upper().replace('_', ' ')}:")
            for key, value in source_data.items():
                if key != "schema_compatible":
                    print(f"   {key}: {value}")
            print()
        
        print(f"üíæ –°–≤–æ–¥–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: data/analysis_summary.json")
        print()
        print("="*70)
        print("‚úÖ –í–´–í–û–î: –¢–µ–∫—É—â–∞—è —Å—Ö–µ–º–∞ –ë–î –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤!")
        print("   –ú–æ–∂–Ω–æ –ø—Ä–∏—Å—Ç—É–ø–∞—Ç—å –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é –≤ Supabase.")
        print("="*70)


def main():
    analyzer = DataAnalyzer()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
    analyzer.analyze_telegram_threads()
    analyzer.analyze_tax_calendar()
    analyzer.analyze_news_articles()
    analyzer.analyze_pdf_documents()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    is_compatible = analyzer.check_db_schema_compatibility()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É
    analyzer.generate_summary()


if __name__ == "__main__":
    main()

