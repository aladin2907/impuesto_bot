#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Å–∫—Ä–∏–ø—Ç—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
"""

import sys
import json
from pathlib import Path
from datetime import datetime


def print_section(title):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å–µ–∫—Ü–∏–∏"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}\n")


def main():
    print_section("–°–ë–û–† –î–ê–ù–ù–´–• –ò–ó –í–°–ï–• –ò–°–¢–û–ß–ù–ò–ö–û–í")
    print(f"üïê –ù–∞—á–∞–ª–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # 1. Telegram —Ç—Ä–µ–¥—ã (—É–∂–µ —Å–∫–∞—á–∞–Ω—ã)
    print_section("1. TELEGRAM –¢–†–ï–î–´")
    print("‚úÖ Telegram —Ç—Ä–µ–¥—ã —É–∂–µ —Å–∫–∞—á–∞–Ω—ã:")
    print("   - it_threads.json (IT Autonomos Spain)")
    print("   - nomads_threads.json (Digital Nomad Spain)")
    print("   - –í—Å–µ–≥–æ: 75,914 —Ç—Ä–µ–¥–æ–≤ (183,856 —Å–æ–æ–±—â–µ–Ω–∏–π)")
    
    # 2. –ù–∞–ª–æ–≥–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å
    print_section("2. –ù–ê–õ–û–ì–û–í–´–ô –ö–ê–õ–ï–ù–î–ê–†–¨ AEAT")
    print("üìÖ –°–∫—Ä–∞–ø–∏–º –Ω–∞–ª–æ–≥–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å...")
    
    try:
        from scrape_tax_calendar import AEATCalendarScraper
        
        scraper = AEATCalendarScraper()
        deadlines = scraper.scrape_calendar(2024)
        
        Path("data").mkdir(exist_ok=True)
        scraper.save_to_json(deadlines, "data/tax_calendar.json")
        scraper.analyze_calendar(deadlines)
        
        print(f"\n‚úÖ –ù–∞–ª–æ–≥–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å —Å–æ–±—Ä–∞–Ω: {len(deadlines)} –¥–µ–¥–ª–∞–π–Ω–æ–≤")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è: {e}")
    
    # 3. –ù–æ–≤–æ—Å—Ç–∏
    print_section("3. –ù–û–í–û–°–¢–ò")
    print("üì∞ –°–∫—Ä–∞–ø–∏–º –Ω–æ–≤–æ—Å—Ç–∏...")
    
    try:
        from scrape_news import NewsScrap
        
        news_scraper = NewsScrap()
        articles = news_scraper.scrape_all_sources(limit_per_source=5)
        
        news_scraper.save_to_json(articles, "data/news_articles.json")
        news_scraper.analyze_articles(articles)
        
        print(f"\n‚úÖ –ù–æ–≤–æ—Å—Ç–∏ —Å–æ–±—Ä–∞–Ω—ã: {len(articles)} —Å—Ç–∞—Ç–µ–π")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
    
    # 4. PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã
    print_section("4. PDF –î–û–ö–£–ú–ï–ù–¢–´")
    print("üìÑ –°–∫–∞—á–∏–≤–∞–µ–º PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
    
    try:
        from download_pdf_documents import PDFDownloader
        
        pdf_downloader = PDFDownloader()
        results = pdf_downloader.download_all_documents("data/pdf_documents")
        
        pdf_downloader.save_metadata(results, "data/pdf_metadata.json")
        pdf_downloader.analyze_documents(results)
        
        successful = sum(1 for r in results if r.get('success'))
        print(f"\n‚úÖ PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–∫–∞—á–∞–Ω—ã: {successful}/{len(results)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ PDF: {e}")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    print_section("–ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó")
    
    stats = {
        "collection_completed_at": datetime.now().isoformat(),
        "sources": {}
    }
    
    # Telegram
    if Path("it_threads.json").exists() and Path("nomads_threads.json").exists():
        with open("it_threads.json") as f:
            it_data = json.load(f)
        with open("nomads_threads.json") as f:
            nomads_data = json.load(f)
        
        stats["sources"]["telegram"] = {
            "status": "collected",
            "groups": 2,
            "total_threads": len(it_data.get("threads", [])) + len(nomads_data.get("threads", [])),
            "total_messages": it_data.get("total_messages", 0) + nomads_data.get("total_messages", 0)
        }
    
    # –ö–∞–ª–µ–Ω–¥–∞—Ä—å
    if Path("data/tax_calendar.json").exists():
        with open("data/tax_calendar.json") as f:
            calendar_data = json.load(f)
        
        stats["sources"]["tax_calendar"] = {
            "status": "collected",
            "total_deadlines": calendar_data.get("total_deadlines", 0)
        }
    
    # –ù–æ–≤–æ—Å—Ç–∏
    if Path("data/news_articles.json").exists():
        with open("data/news_articles.json") as f:
            news_data = json.load(f)
        
        stats["sources"]["news"] = {
            "status": "collected",
            "total_articles": news_data.get("total_articles", 0),
            "sources": news_data.get("sources", [])
        }
    
    # PDF
    if Path("data/pdf_metadata.json").exists():
        with open("data/pdf_metadata.json") as f:
            pdf_data = json.load(f)
        
        stats["sources"]["pdf_documents"] = {
            "status": "collected",
            "total_documents": pdf_data.get("total_documents", 0),
            "successful_downloads": pdf_data.get("successful_downloads", 0)
        }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    with open("data/collection_stats.json", 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print("üìä –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:\n")
    
    for source_name, source_data in stats["sources"].items():
        print(f"‚úÖ {source_name.upper()}:")
        for key, value in source_data.items():
            if key != "status":
                print(f"   - {key}: {value}")
        print()
    
    print(f"üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: data/collection_stats.json")
    
    print_section("–ó–ê–í–ï–†–®–ï–ù–û")
    print(f"üïê –û–∫–æ–Ω—á–∞–Ω–∏–µ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\n‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∞–Ω–∞–ª–∏–∑—É!")
    print("\n–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏")
    print("—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ö–µ–º—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.\n")


if __name__ == "__main__":
    main()

