#!/usr/bin/env python3
"""
–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ Elasticsearch
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Inference API –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from elasticsearch import Elasticsearch
from app.config.settings import Settings

settings = Settings()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
# API key format: "id:api_key" –∏–ª–∏ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –∫–æ—Ä—Ç–µ–∂
api_key_parts = settings.ELASTIC_API_KEY.split(':') if ':' in settings.ELASTIC_API_KEY else None
client = Elasticsearch(
    "https://36d0e937f1fd4309a2cb624f5f11bed1.us-central1.gcp.cloud.es.io:443",
    api_key=(api_key_parts[0], api_key_parts[1]) if api_key_parts else settings.ELASTIC_API_KEY,
    request_timeout=60  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º timeout –¥–ª—è inference
)

# Inference model –¥–ª—è embeddings (–º–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å)
INFERENCE_ID = ".multilingual-e5-small-elasticsearch"

# –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
INDICES = {
    "telegram_threads": {
        "text_field": "content",
        "embedding_field": "content_embedding"
    },
    "pdf_documents": {
        "text_field": "content",
        "embedding_field": "content_embedding"
    },
    "calendar_deadlines": {
        "text_field": "description",
        "embedding_field": "description_embedding"
    },
    "news_articles": {
        "text_field": "content",
        "embedding_field": "content_embedding"
    }
}


def add_inference_pipeline(index_name: str, text_field: str, embedding_field: str):
    """–°–æ–∑–¥–∞–µ—Ç inference pipeline –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings"""
    
    pipeline_id = f"{index_name}_inference_pipeline"
    
    pipeline_config = {
        "description": f"Inference pipeline for {index_name}",
        "processors": [
            {
                "inference": {
                    "model_id": INFERENCE_ID,
                    "input_output": {
                        "input_field": text_field,
                        "output_field": embedding_field
                    }
                }
            }
        ]
    }
    
    try:
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π pipeline –µ—Å–ª–∏ –µ—Å—Ç—å
        try:
            client.ingest.delete_pipeline(id=pipeline_id)
            print(f"  –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π pipeline: {pipeline_id}")
        except:
            pass
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π pipeline
        client.ingest.put_pipeline(id=pipeline_id, body=pipeline_config)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω pipeline: {pipeline_id}")
        return pipeline_id
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è pipeline: {e}")
        return None


def update_index_mapping(index_name: str, embedding_field: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª–µ dense_vector –≤ mapping –∏–Ω–¥–µ–∫—Å–∞"""
    
    mapping = {
        "properties": {
            embedding_field: {
                "type": "dense_vector",
                "dims": 384,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è multilingual-e5-small
                "index": True,
                "similarity": "cosine"
            }
        }
    }
    
    try:
        client.indices.put_mapping(index=index_name, body=mapping)
        print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω mapping –¥–ª—è {index_name}")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è mapping: {e}")
        return False


def configure_index_for_hybrid_search(index_name: str, text_field: str, embedding_field: str):
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    
    print(f"\nüîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è {index_name}...")
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    if not client.indices.exists(index=index_name):
        print(f"‚ö†Ô∏è  –ò–Ω–¥–µ–∫—Å {index_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return False
    
    # 2. –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è embeddings
    if not update_index_mapping(index_name, embedding_field):
        return False
    
    # 3. –°–æ–∑–¥–∞–µ–º inference pipeline
    pipeline_id = add_inference_pipeline(index_name, text_field, embedding_field)
    if not pipeline_id:
        return False
    
    # 4. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º default pipeline –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    try:
        client.indices.put_settings(
            index=index_name,
            body={
                "index": {
                    "default_pipeline": pipeline_id
                }
            }
        )
        print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω default pipeline –¥–ª—è {index_name}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ default pipeline: {e}")
        return False
    
    print(f"‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è {index_name}")
    return True


def test_inference():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º inference –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ inference...")
    
    test_text = "IVA declaraci√≥n trimestral modelo 303"
    
    try:
        result = client.inference.inference(
            inference_id=INFERENCE_ID,
            body={
                "input": test_text
            }
        )
        
        embedding = result['results'][0]['embedding']
        print(f"‚úÖ Inference —Ä–∞–±–æ—Ç–∞–µ—Ç!")
        print(f"  –¢–µ–∫—Å—Ç: {test_text}")
        print(f"  –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞: {len(embedding)}")
        print(f"  –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π: {embedding[:5]}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ inference: {e}")
        return False


def main():
    print("=" * 60)
    print("üöÄ –ù–ê–°–¢–†–û–ô–ö–ê –ì–ò–ë–†–ò–î–ù–û–ì–û –ü–û–ò–°–ö–ê –í ELASTICSEARCH")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    try:
        info = client.info()
        print(f"\n‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω –∫ Elasticsearch {info['version']['number']}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return 1
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º inference
    if not test_inference():
        print("\n‚ùå Inference –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É")
        return 1
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∏–Ω–¥–µ–∫—Å
    print("\n" + "=" * 60)
    print("üì¶ –ù–ê–°–¢–†–û–ô–ö–ê –ò–ù–î–ï–ö–°–û–í")
    print("=" * 60)
    
    success_count = 0
    for index_name, config in INDICES.items():
        if configure_index_for_hybrid_search(
            index_name=index_name,
            text_field=config["text_field"],
            embedding_field=config["embedding_field"]
        ):
            success_count += 1
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 60)
    print(f"‚úÖ –ì–û–¢–û–í–û: {success_count}/{len(INDICES)} –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
    print("=" * 60)
    
    print("\nüìã –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
    print("1. –†–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings:")
    print("   python scripts/reindex_with_embeddings.py")
    print("")
    print("2. –û–±–Ω–æ–≤–∏—Ç—å search_service.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("")
    print("3. –ù–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞—Ç—å embeddings –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

